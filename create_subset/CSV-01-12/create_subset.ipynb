{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "chunksize = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrDoS_DNS = pd.read_csv('../CSV-01-12/01-12/DrDoS_DNS.csv', chunksize=chunksize)\n",
    "DrDoS_LDAP = pd.read_csv('../CSV-01-12/01-12/DrDoS_LDAP.csv', chunksize=chunksize)\n",
    "DrDoS_MSSQL = pd.read_csv('../CSV-01-12/01-12/DrDoS_MSSQL.csv', chunksize=chunksize)\n",
    "DrDoS_NetBIOS = pd.read_csv('../CSV-01-12/01-12/DrDoS_NetBIOS.csv', chunksize=chunksize)\n",
    "DrDoS_NTP = pd.read_csv('../CSV-01-12/01-12/DrDoS_NTP.csv', chunksize=chunksize)\n",
    "DrDoS_SNMP = pd.read_csv('../CSV-01-12/01-12/DrDoS_SNMP.csv', chunksize=chunksize)\n",
    "DrDoS_SSDP = pd.read_csv('../CSV-01-12/01-12/DrDoS_SSDP.csv', chunksize=chunksize)\n",
    "DrDoS_UDP = pd.read_csv('../CSV-01-12/01-12/DrDoS_UDP.csv', chunksize=chunksize)\n",
    "Syn = pd.read_csv('../CSV-01-12/01-12/Syn.csv', chunksize=chunksize)\n",
    "TFTP = pd.read_csv('../CSV-01-12/01-12/TFTP.csv', chunksize=chunksize)\n",
    "UDPLag = pd.read_csv('../CSV-01-12/01-12/UDPLag.csv', chunksize=chunksize)\n",
    "csv_list = [DrDoS_DNS, DrDoS_LDAP, DrDoS_MSSQL, DrDoS_NetBIOS, DrDoS_NTP, DrDoS_SNMP, DrDoS_SSDP, DrDoS_UDP, Syn, TFTP, UDPLag] # csv file list\n",
    "csv_label_name = ['DrDoS_DNS', 'DrDoS_LDAP', 'DrDoS_MSSQL', 'DrDoS_NetBIOS', 'DrDoS_NTP', 'DrDoS_SNMP', 'DrDoS_SSDP', 'DrDoS_UDP', 'Syn', 'TFTP', 'UDP-lag'] # name of each csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_num = [] # number of benign packet in each csv file\n",
    "ddos_num = [] # number of ddos packet in each csv file\n",
    "other_num = [] # number of other packet in each csv file, it should be zero\n",
    "\n",
    "csv_name_index = 0 # index\n",
    "for csv in csv_list: # retrieve all csv file\n",
    "    benign = 0 # count for benign packet\n",
    "    ddos = 0\n",
    "    other = 0\n",
    "    current_csv_name = csv_label_name[csv_name_index]\n",
    "    csv_name_index += 1\n",
    "    for df in csv:\n",
    "        for i in range(0, df.shape[0]):\n",
    "            current_label = df[' Label'].iloc[i] # column name has one space in the front\n",
    "            if current_label == 'BENIGN':\n",
    "                benign += 1\n",
    "            elif current_label == current_csv_name:\n",
    "                ddos += 1\n",
    "            else:\n",
    "                other += 1\n",
    "    benign_num.append(benign)\n",
    "    ddos_num.append(ddos)\n",
    "    other_num.append(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrDoS_DNS = pd.read_csv('../../../CSV-01-12/01-12/DrDoS_DNS.csv', chunksize=chunksize)\n",
    "DrDoS_LDAP = pd.read_csv('../../../CSV-01-12/01-12/DrDoS_LDAP.csv', chunksize=chunksize)\n",
    "DrDoS_MSSQL = pd.read_csv('../../../CSV-01-12/01-12/DrDoS_MSSQL.csv', chunksize=chunksize)\n",
    "DrDoS_NetBIOS = pd.read_csv('../../../CSV-01-12/01-12/DrDoS_NetBIOS.csv', chunksize=chunksize)\n",
    "DrDoS_NTP = pd.read_csv('../../../CSV-01-12/01-12/DrDoS_NTP.csv', chunksize=chunksize)\n",
    "DrDoS_SNMP = pd.read_csv('../../../CSV-01-12/01-12/DrDoS_SNMP.csv', chunksize=chunksize)\n",
    "DrDoS_SSDP = pd.read_csv('../../../CSV-01-12/01-12/DrDoS_SSDP.csv', chunksize=chunksize)\n",
    "DrDoS_UDP = pd.read_csv('../../../CSV-01-12/01-12/DrDoS_UDP.csv', chunksize=chunksize)\n",
    "Syn = pd.read_csv('../../../CSV-01-12/01-12/Syn.csv', chunksize=chunksize)\n",
    "TFTP = pd.read_csv('../../../CSV-01-12/01-12/TFTP.csv', chunksize=chunksize)\n",
    "UDPLag = pd.read_csv('../../../CSV-01-12/01-12/UDPLag.csv', chunksize=chunksize)\n",
    "csv_list = [DrDoS_DNS, DrDoS_LDAP, DrDoS_MSSQL, DrDoS_NetBIOS, DrDoS_NTP, DrDoS_SNMP, DrDoS_SSDP, DrDoS_UDP, Syn, TFTP, UDPLag] # csv file list\n",
    "csv_label_name = ['DrDoS_DNS', 'DrDoS_LDAP', 'DrDoS_MSSQL', 'DrDoS_NetBIOS', 'DrDoS_NTP', 'DrDoS_SNMP', 'DrDoS_SSDP', 'DrDoS_UDP', 'Syn', 'TFTP', 'UDP-lag'] # name of each csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name_index = 0\n",
    "for csv in csv_list:\n",
    "    subset_csv = pd.DataFrame() # empty dataframe, for collect subset packet in each csv file\n",
    "    benign = 0 # number of benign currently get\n",
    "    ddos = 0\n",
    "    current_packet_num = benign_num[csv_name_index] # number of benign packet in each csv file. our target number\n",
    "    current_csv_name = csv_label_name[csv_name_index]\n",
    "    csv_name_index += 1\n",
    "    result_num = []\n",
    "    for df in csv:\n",
    "        for i in range(0, df.shape[0]):\n",
    "            current_label = df[' Label'].iloc[i] # column name has space\n",
    "            row = df.iloc[[i]] # series class\n",
    "            if current_label == 'BENIGN' and benign != current_packet_num:\n",
    "                subset_csv = pd.concat([subset_csv, row], axis=0)\n",
    "                benign += 1\n",
    "            elif current_label == current_csv_name and ddos != current_packet_num:\n",
    "                subset_csv = pd.concat([subset_csv, row], axis=0)\n",
    "                ddos += 1\n",
    "            elif ddos == current_packet_num and benign == current_packet_num:\n",
    "                break\n",
    "        if ddos == current_packet_num and benign == current_packet_num:\n",
    "            break\n",
    "        \n",
    "    result_num.append(ddos+benign)\n",
    "    subset_csv.to_csv('subset' + current_csv_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n",
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n",
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n",
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n",
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n",
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n",
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n",
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n",
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n",
      "/tmp/ipykernel_44268/3796118081.py:4: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for df in UDPLag:\n"
     ]
    }
   ],
   "source": [
    "# for WebDDoS subset only\n",
    "UDPLag = pd.read_csv('../../../CSV-01-12/01-12/UDPLag.csv', chunksize=chunksize)\n",
    "subset_csv = pd.DataFrame() # empty dataframe, for collect subset packet in each csv file\n",
    "for df in UDPLag:\n",
    "    for i in range(0, df.shape[0]):\n",
    "        current_label = df[' Label'].iloc[i] # column name has space\n",
    "        row = df.iloc[[i]] # series class\n",
    "        if current_label == 'WebDDoS' :\n",
    "            subset_csv = pd.concat([subset_csv, row], axis=0)\n",
    "    \n",
    "subset_csv.to_csv('subsetWebDDoS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3534/2630055600.py:14: DtypeWarning: Columns (86) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  c = pd.read_csv(f, index_col=0)\n",
      "/tmp/ipykernel_3534/2630055600.py:14: DtypeWarning: Columns (86) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  c = pd.read_csv(f, index_col=0)\n",
      "/tmp/ipykernel_3534/2630055600.py:14: DtypeWarning: Columns (86) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  c = pd.read_csv(f, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "# Combine all subset exclude subsetWebDDoS\n",
    "# source: https://www.askpython.com/python-modules/pandas/combine-csv-files-using-python\n",
    "import glob\n",
    " \n",
    "# list all csv files only\n",
    "csv_files = glob.glob('*.{}'.format('csv'))\n",
    "csv_files.remove('subsetWebDDoS.csv') # we don't want subsetWebDDoS now\n",
    "csv_files\n",
    "\n",
    "l = []\n",
    "\n",
    "# read without first column('unamed')\n",
    "for f in csv_files:\n",
    "    c = pd.read_csv(f, index_col=0)\n",
    "    c = c.drop('Unnamed: 0', axis=1)\n",
    "    l.append(c)\n",
    "     \n",
    "df_res = pd.concat(l, ignore_index=True)\n",
    "df_res.to_csv('merge_subset_exclude_webddos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# You can use this method to count subset dataset number fast\n",
    "\n",
    "count = 0\n",
    "file = open('./subsetDrDoS_NetBIOS.csv', 'r', encoding='utf-8')\n",
    "while 1:\n",
    "    buffer = file.read(8*1024*1024)\n",
    "    if not buffer:\n",
    "        break\n",
    "    count += buffer.count('\\n')\n",
    "print(count)\n",
    "file.close()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autopytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f8b18ae7794193a368c50ff41dfdcf1c6a3e6bc08764bfb820b01662cfc5089"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
